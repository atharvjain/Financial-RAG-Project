{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd83cf50-0fab-4709-9ec0-d2abb4db378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded 4000 rows, 50 companies\n",
      "INFO:__main__:Generated 3500 test queries\n",
      "INFO:__main__:Saved files to: /root/nfs/AJ FinRag/Evaluation/Test Queries\n",
      "INFO:__main__:Generated 3500 test queries\n",
      "INFO:__main__:Filtered to 2642 rise/fall queries\n",
      "INFO:__main__:Created sample with 50 queries\n",
      "INFO:__main__:Complete: 3500 total, 2642 rise/fall, 50 sample\n",
      "INFO:__main__:Distribution: Rise=1382, Fall=1260, Freeze=858\n"
     ]
    }
   ],
   "source": [
    "#TEST DATASET\n",
    "# Test Query Generator - Create queries without movement + separate ground truth\n",
    "# For testing FinQuest on new 2024-12-20 to 2025-03-31 data\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TestQueryGenerator:\n",
    "    \"\"\"\n",
    "    Generate test queries without movement labels and separate ground truth file\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, test_processed_data_path, output_dir=\"test_queries\"):\n",
    "        self.test_processed_data_path = test_processed_data_path\n",
    "        self.output_dir = output_dir\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load test data\n",
    "        self.df = pd.read_json(test_processed_data_path, lines=True)\n",
    "        self.df['date'] = pd.to_datetime(self.df['date'])\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.df)} rows, {self.df['ticker'].nunique()} companies\")\n",
    "        \n",
    "    def generate_test_queries_and_ground_truth(self):\n",
    "        \"\"\"\n",
    "        Generate test queries (without movement) and separate ground truth file\n",
    "        \"\"\"\n",
    "        test_queries = []\n",
    "        ground_truth = []\n",
    "        \n",
    "        # Process each company separately\n",
    "        for ticker in self.df['ticker'].unique():\n",
    "            # Get company data sorted by date\n",
    "            company_data = self.df[self.df['ticker'] == ticker].sort_values('date').reset_index(drop=True)\n",
    "            \n",
    "            # Need at least 11 days (10 for history + 1 for prediction)\n",
    "            if len(company_data) < 11:\n",
    "                continue\n",
    "            \n",
    "            # Generate queries starting from day 11 (need 10-day history)\n",
    "            for i in range(10, len(company_data)):\n",
    "                current_date = company_data.loc[i, 'date']\n",
    "                \n",
    "                # Get 10-day history (days i-10 to i-1)\n",
    "                history_data = company_data.loc[i-10:i-1]\n",
    "                \n",
    "                # Create test query (WITHOUT movement)\n",
    "                test_query = {\n",
    "                    'query_id': f\"{ticker}_{current_date.strftime('%Y-%m-%d')}\",\n",
    "                    'query_stock': ticker,\n",
    "                    'query_date': current_date.strftime('%Y-%m-%d'),\n",
    "                    'recent_date_list': [d.strftime('%Y-%m-%d') for d in history_data['date']],\n",
    "                    'adjusted_close_list': [round(float(v), 4) if pd.notna(v) else 0.0 \n",
    "                                          for v in history_data['adj_close']],\n",
    "                    'data_index': len(test_queries)\n",
    "                }\n",
    "                \n",
    "                # Create ground truth entry (WITH movement)\n",
    "                actual_movement = self._get_movement(company_data.loc[i])\n",
    "                \n",
    "                ground_truth_entry = {\n",
    "                    'query_id': f\"{ticker}_{current_date.strftime('%Y-%m-%d')}\",\n",
    "                    'query_stock': ticker,\n",
    "                    'query_date': current_date.strftime('%Y-%m-%d'),\n",
    "                    'actual_movement': actual_movement,\n",
    "                    'actual_return': float(company_data.loc[i, 'Returns'] * 100) if pd.notna(company_data.loc[i, 'Returns']) else 0.0,\n",
    "                    'actual_close': float(company_data.loc[i, 'adj_close']),\n",
    "                    'previous_close': float(company_data.loc[i-1, 'adj_close']) if i > 0 else 0.0,\n",
    "                    'data_index': len(ground_truth)\n",
    "                }\n",
    "                \n",
    "                test_queries.append(test_query)\n",
    "                ground_truth.append(ground_truth_entry)\n",
    "        \n",
    "        logger.info(f\"Generated {len(test_queries)} test queries\")\n",
    "        return test_queries, ground_truth\n",
    "    \n",
    "    def _get_movement(self, row):\n",
    "        \"\"\"Determine movement from returns (same logic as training)\"\"\"\n",
    "        return_val = row.get('Returns', 0) * 100\n",
    "        if pd.isna(return_val):\n",
    "            return 'freeze'\n",
    "        if return_val > 0.55:\n",
    "            return 'rise'\n",
    "        elif return_val < -0.5:\n",
    "            return 'fall'\n",
    "        else:\n",
    "            return 'freeze'\n",
    "    \n",
    "    def save_test_files(self, test_queries, ground_truth):\n",
    "        \"\"\"Save test queries and ground truth to separate files\"\"\"\n",
    "        \n",
    "        # Save test queries (for prediction)\n",
    "        test_queries_file = Path(self.output_dir) / \"test_queries.json\"\n",
    "        with open(test_queries_file, 'w') as f:\n",
    "            for query in test_queries:\n",
    "                f.write(json.dumps(query) + '\\n')\n",
    "        \n",
    "        # Save ground truth (for evaluation)\n",
    "        ground_truth_file = Path(self.output_dir) / \"ground_truth.json\"\n",
    "        with open(ground_truth_file, 'w') as f:\n",
    "            for gt in ground_truth:\n",
    "                f.write(json.dumps(gt) + '\\n')\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'total_queries': len(test_queries),\n",
    "            'total_companies': len(set(q['query_stock'] for q in test_queries)),\n",
    "            'movement_distribution': self._analyze_movement_distribution(ground_truth),\n",
    "            'created_at': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        metadata_file = Path(self.output_dir) / \"test_metadata.json\"\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Saved files to: {self.output_dir}\")\n",
    "        return test_queries_file, ground_truth_file, metadata_file\n",
    "    \n",
    "    def _analyze_movement_distribution(self, ground_truth):\n",
    "        \"\"\"Analyze distribution of movements in ground truth\"\"\"\n",
    "        movements = [gt['actual_movement'] for gt in ground_truth]\n",
    "        return {\n",
    "            'rise': movements.count('rise'),\n",
    "            'fall': movements.count('fall'),\n",
    "            'freeze': movements.count('freeze'),\n",
    "            'total': len(movements)\n",
    "        }\n",
    "    \n",
    "    def create_filtered_test_queries(self, exclude_freeze=True):\n",
    "        \"\"\"\n",
    "        Create filtered test queries (optionally exclude freeze movements)\n",
    "        \"\"\"\n",
    "        test_queries, ground_truth = self.generate_test_queries_and_ground_truth()\n",
    "        \n",
    "        if exclude_freeze:\n",
    "            # Filter out freeze movements\n",
    "            filtered_pairs = []\n",
    "            for query, gt in zip(test_queries, ground_truth):\n",
    "                if gt['actual_movement'] in ['rise', 'fall']:\n",
    "                    filtered_pairs.append((query, gt))\n",
    "            \n",
    "            if filtered_pairs:\n",
    "                filtered_test_queries, filtered_ground_truth = zip(*filtered_pairs)\n",
    "                filtered_test_queries = list(filtered_test_queries)\n",
    "                filtered_ground_truth = list(filtered_ground_truth)\n",
    "                \n",
    "                # Update indices\n",
    "                for i, (query, gt) in enumerate(zip(filtered_test_queries, filtered_ground_truth)):\n",
    "                    query['data_index'] = i\n",
    "                    gt['data_index'] = i\n",
    "            else:\n",
    "                filtered_test_queries, filtered_ground_truth = [], []\n",
    "            \n",
    "            # Save filtered versions\n",
    "            filtered_queries_file = Path(self.output_dir) / \"test_queries_rise_fall_only.json\"\n",
    "            with open(filtered_queries_file, 'w') as f:\n",
    "                for query in filtered_test_queries:\n",
    "                    f.write(json.dumps(query) + '\\n')\n",
    "            \n",
    "            filtered_gt_file = Path(self.output_dir) / \"ground_truth_rise_fall_only.json\"\n",
    "            with open(filtered_gt_file, 'w') as f:\n",
    "                for gt in filtered_ground_truth:\n",
    "                    f.write(json.dumps(gt) + '\\n')\n",
    "            \n",
    "            logger.info(f\"Filtered to {len(filtered_test_queries)} rise/fall queries\")\n",
    "            return filtered_test_queries, filtered_ground_truth, filtered_queries_file, filtered_gt_file\n",
    "        \n",
    "        return test_queries, ground_truth, None, None\n",
    "\n",
    "def create_sample_queries_for_quick_test(test_queries_file, num_samples=50, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a small sample of test queries for quick testing\n",
    "    \"\"\"\n",
    "    # Load test queries\n",
    "    test_queries = []\n",
    "    with open(test_queries_file, 'r') as f:\n",
    "        for line in f:\n",
    "            test_queries.append(json.loads(line.strip()))\n",
    "    \n",
    "    # Sample queries (spread across different stocks and dates)\n",
    "    if len(test_queries) <= num_samples:\n",
    "        sample_queries = test_queries\n",
    "    else:\n",
    "        # Try to get diverse sample across stocks and dates\n",
    "        stocks = list(set(q['query_stock'] for q in test_queries))\n",
    "        queries_per_stock = max(1, num_samples // len(stocks))\n",
    "        \n",
    "        sample_queries = []\n",
    "        for stock in stocks:\n",
    "            stock_queries = [q for q in test_queries if q['query_stock'] == stock]\n",
    "            if stock_queries:\n",
    "                # Take evenly spaced queries from this stock\n",
    "                step = max(1, len(stock_queries) // queries_per_stock)\n",
    "                stock_sample = stock_queries[::step][:queries_per_stock]\n",
    "                sample_queries.extend(stock_sample)\n",
    "        \n",
    "        # If we still need more, add random ones\n",
    "        if len(sample_queries) < num_samples:\n",
    "            remaining = [q for q in test_queries if q not in sample_queries]\n",
    "            import random\n",
    "            additional = random.sample(remaining, min(num_samples - len(sample_queries), len(remaining)))\n",
    "            sample_queries.extend(additional)\n",
    "    \n",
    "    # Update indices\n",
    "    for i, query in enumerate(sample_queries):\n",
    "        query['data_index'] = i\n",
    "    \n",
    "    # Save sample\n",
    "    if output_file is None:\n",
    "        output_file = str(Path(test_queries_file).parent / \"test_queries_sample.json\")\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for query in sample_queries:\n",
    "            f.write(json.dumps(query) + '\\n')\n",
    "    \n",
    "    logger.info(f\"Created sample with {len(sample_queries)} queries\")\n",
    "    return sample_queries, output_file\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to generate test queries and ground truth\n",
    "    \"\"\"\n",
    "    # Configuration - UPDATE THIS PATH\n",
    "    config = {\n",
    "        'test_processed_data_path': '/root/nfs/AJ FinRag/Test Data/Company Processed Test Data/all_companies_processed.json',  # Your new test data\n",
    "        'output_dir': '/root/nfs/AJ FinRag/Evaluation Results/Test Queries'\n",
    "    }\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = TestQueryGenerator(\n",
    "        test_processed_data_path=config['test_processed_data_path'],\n",
    "        output_dir=config['output_dir']\n",
    "    )\n",
    "    \n",
    "    # Generate all test queries and ground truth\n",
    "    test_queries, ground_truth = generator.generate_test_queries_and_ground_truth()\n",
    "    test_file, gt_file, metadata_file = generator.save_test_files(test_queries, ground_truth)\n",
    "    \n",
    "    # Generate filtered queries (rise/fall only)\n",
    "    filtered_queries, filtered_gt, filtered_test_file, filtered_gt_file = generator.create_filtered_test_queries(exclude_freeze=True)\n",
    "    \n",
    "    # Create sample for quick testing\n",
    "    if filtered_test_file:\n",
    "        sample_queries, sample_file = create_sample_queries_for_quick_test(filtered_test_file, num_samples=50)\n",
    "    else:\n",
    "        sample_queries, sample_file = create_sample_queries_for_quick_test(test_file, num_samples=50)\n",
    "    \n",
    "    # Summary\n",
    "    movement_dist = generator._analyze_movement_distribution(ground_truth)\n",
    "    logger.info(f\"Complete: {len(test_queries)} total, {len(filtered_queries) if filtered_queries else 0} rise/fall, {len(sample_queries)} sample\")\n",
    "    logger.info(f\"Distribution: Rise={movement_dist['rise']}, Fall={movement_dist['fall']}, Freeze={movement_dist['freeze']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f4154-7e24-4d60-a19c-992ff2e842e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
