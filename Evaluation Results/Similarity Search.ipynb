{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4567bf-d960-491c-8d53-2a177be04550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üöÄ Starting Retrieval-Based Similarity Search\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:‚úÖ All files found - proceeding with search\n",
      "INFO:__main__:‚úÖ Test queries: /root/nfs/AJ FinRag/Evaluation Results/Test Queries/test_queries_rise_fall_only.json\n",
      "INFO:__main__:‚úÖ Query embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/q_your_dataset_FinQuest_embeddings.pkl\n",
      "INFO:__main__:‚úÖ Candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest\n",
      "INFO:__main__:‚úÖ Model: /root/nfs/AJ FinRag/Models/finquest_models/finquest_retriever_best.pth\n",
      "INFO:__main__:Loaded FinQuest model from: /root/nfs/AJ FinRag/Models/finquest_models/finquest_retriever_best.pth\n",
      "INFO:__main__:Loading query embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/q_your_dataset_FinQuest_embeddings.pkl\n",
      "INFO:__main__:Successfully loaded 742 historical queries\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_1.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_2.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_3.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_4.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_5.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_6.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_7.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_8.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_9.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_10.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_11.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_12.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_13.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_14.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_15.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_16.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_17.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_18.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_19.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_20.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_21.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_22.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_23.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_24.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_25.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_26.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_27.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_28.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_29.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_30.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_31.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_32.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_33.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_34.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_35.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_36.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_37.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_38.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_39.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_40.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_41.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_42.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_43.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_44.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_45.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_46.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_47.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_48.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_49.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_50.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_51.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_52.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_53.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_54.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_55.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_56.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_57.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_58.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_59.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_60.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_61.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_62.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_63.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_64.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_65.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_66.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_67.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_68.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_69.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_70.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_71.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_72.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_73.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_74.pkl\n",
      "INFO:__main__:Loading candidate embeddings: /root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest/c_your_dataset_FinQuest_embeddings_75.pkl\n",
      "INFO:__main__:Successfully loaded 75 candidate embedding files with 8151 total candidates\n",
      "INFO:__main__:Creating query-candidate mapping based on dates and stocks...\n",
      "INFO:__main__:Mapping Statistics:\n",
      "INFO:__main__:  Total historical queries: 742\n",
      "INFO:__main__:  Queries with candidates: 532 (71.7%)\n",
      "INFO:__main__:  Average candidates per query: 31.8\n",
      "INFO:__main__:  Max candidates for any query: 44\n",
      "INFO:__main__:Loaded 2642 test queries\n",
      "INFO:__main__:Loaded 742 historical queries\n",
      "INFO:__main__:Loaded 8151 candidates\n",
      "INFO:__main__:Created mapping for 532 queries\n",
      "INFO:__main__:Running similarity search...\n",
      "INFO:__main__:Processing 2642 test queries...\n",
      "/tmp/ipykernel_822/2419396194.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "INFO:__main__:Processed 100/2642 queries\n",
      "INFO:__main__:Processed 200/2642 queries\n",
      "INFO:__main__:Processed 300/2642 queries\n",
      "INFO:__main__:Processed 400/2642 queries\n",
      "INFO:__main__:Processed 500/2642 queries\n",
      "INFO:__main__:Processed 600/2642 queries\n",
      "INFO:__main__:Processed 700/2642 queries\n",
      "INFO:__main__:Processed 800/2642 queries\n",
      "INFO:__main__:Processed 900/2642 queries\n",
      "INFO:__main__:Processed 1000/2642 queries\n",
      "INFO:__main__:Processed 1100/2642 queries\n",
      "INFO:__main__:Processed 1200/2642 queries\n",
      "INFO:__main__:Processed 1300/2642 queries\n",
      "INFO:__main__:Processed 1400/2642 queries\n",
      "INFO:__main__:Processed 1500/2642 queries\n",
      "INFO:__main__:Processed 1600/2642 queries\n",
      "INFO:__main__:Processed 1700/2642 queries\n",
      "INFO:__main__:Processed 1800/2642 queries\n",
      "INFO:__main__:Processed 1900/2642 queries\n",
      "INFO:__main__:Processed 2000/2642 queries\n",
      "INFO:__main__:Processed 2100/2642 queries\n",
      "INFO:__main__:Processed 2200/2642 queries\n",
      "INFO:__main__:Processed 2300/2642 queries\n",
      "INFO:__main__:Processed 2400/2642 queries\n",
      "INFO:__main__:Processed 2500/2642 queries\n",
      "INFO:__main__:Processed 2600/2642 queries\n",
      "INFO:__main__:Completed similarity search for 2642 test queries\n",
      "INFO:__main__:Queries with candidates found: 2642/2642 (100.0%)\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:RETRIEVAL-BASED SEARCH RESULTS ANALYSIS\n",
      "INFO:__main__:==================================================\n",
      "INFO:__main__:Total test queries processed: 2642\n",
      "INFO:__main__:Queries with candidates found: 2642 (100.0%)\n",
      "INFO:__main__:Queries with no candidates: 0\n",
      "INFO:__main__:Average candidates per successful query: 10.0\n",
      "INFO:__main__:Max candidates for any query: 10\n",
      "INFO:__main__:Min candidates for successful queries: 10\n",
      "INFO:__main__:\n",
      "SAMPLE SUCCESSFUL RESULT:\n",
      "INFO:__main__:Test query: AAPL on 2025-01-17\n",
      "INFO:__main__:Found 10 candidates\n",
      "INFO:__main__:Top candidate: Index 44 (score: 1.000)\n",
      "INFO:__main__:Saved results to: similar_candidates/test/FinQuest/test_similarity_results_FinQuest.pkl\n",
      "INFO:__main__:üéâ Retrieval-based similarity search completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# FIXED Query-to-Query Similarity Search for FinQuest\n",
    "# Addresses all alignment issues with your embedding generation code\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Disable warnings (same as your embedding code)\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "class FinQuestRetriever(torch.nn.Module):\n",
    "    \"\"\"Your custom trained FinQuest model - EXACT COPY from embedding code\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', hidden_size=384, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        from transformers import AutoModel\n",
    "        \n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        encoder_dim = self.encoder.config.hidden_size\n",
    "        self.projection = torch.nn.Sequential(\n",
    "            torch.nn.Linear(encoder_dim, hidden_size * 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size),\n",
    "            torch.nn.LayerNorm(hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.financial_attention = torch.nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def encode_sequence(self, sequences):\n",
    "        \"\"\"Encode sequences using FinQuest model - EXACT COPY\"\"\"\n",
    "        if not sequences or all(not seq.strip() for seq in sequences):\n",
    "            return torch.zeros(len(sequences), self.hidden_size).to(next(self.parameters()).device)\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            sequences,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(next(self.parameters()).device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = self.encoder(**inputs)\n",
    "            embeddings = self.mean_pooling(outputs, inputs['attention_mask'])\n",
    "        \n",
    "        projected = self.projection(embeddings.float())\n",
    "        attended, _ = self.financial_attention(\n",
    "            projected.unsqueeze(1),\n",
    "            projected.unsqueeze(1), \n",
    "            projected.unsqueeze(1)\n",
    "        )\n",
    "        attended = attended.squeeze(1)\n",
    "        \n",
    "        return torch.nn.functional.normalize(self.dropout(attended), p=2, dim=1)\n",
    "    \n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"Mean pooling with attention mask - EXACT COPY\"\"\"\n",
    "        token_embeddings = model_output.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "class RetrievalBasedSimilaritySearch:\n",
    "    \"\"\"\n",
    "    FIXED: Retrieval-based similarity search using your existing embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, test_queries_file, test_dataset='your_dataset', embedder_name='FinQuest', device='cuda'):\n",
    "        self.test_dataset = test_dataset\n",
    "        self.embedder_name = embedder_name\n",
    "        self.device = device\n",
    "        self.root = '/root/nfs/AJ FinRag/Models/'\n",
    "        \n",
    "        # Load model (same as your EMBEDDER class)\n",
    "        self.model = self._load_finquest_model()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Load test queries\n",
    "        self.test_queries = self._load_test_queries(test_queries_file)\n",
    "        \n",
    "        # Load existing embeddings (using your exact file structure)\n",
    "        self.embeddings_dir = '/root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest'\n",
    "        self.historical_queries = self._load_historical_query_embeddings()\n",
    "        self.candidates = self._load_candidate_embeddings()\n",
    "        \n",
    "        # Create query-candidate mapping\n",
    "        self.query_candidate_mapping = self._create_query_candidate_mapping()\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.test_queries)} test queries\")\n",
    "        logger.info(f\"Loaded {len(self.historical_queries)} historical queries\")\n",
    "        logger.info(f\"Loaded {len(self.candidates)} candidates\")\n",
    "        logger.info(f\"Created mapping for {len(self.query_candidate_mapping)} queries\")\n",
    "    \n",
    "    def _load_finquest_model(self):\n",
    "        \"\"\"Load your trained FinQuest model - EXACT COPY from EMBEDDER\"\"\"\n",
    "        model_path = os.path.join(self.root, 'finquest_models/finquest_retriever_best.pth')\n",
    "        model = FinQuestRetriever().to(self.device)\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        model.eval()\n",
    "        logger.info(f\"Loaded FinQuest model from: {model_path}\")\n",
    "        return model\n",
    "    \n",
    "    def _load_test_queries(self, test_queries_file):\n",
    "        \"\"\"Load new test queries - FIXED: Better error handling\"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        if not os.path.exists(test_queries_file):\n",
    "            logger.error(f\"Test queries file not found: {test_queries_file}\")\n",
    "            return queries\n",
    "            \n",
    "        try:\n",
    "            with open(test_queries_file, 'r', encoding='utf-8') as f:\n",
    "                for line_num, line in enumerate(f, 1):\n",
    "                    try:\n",
    "                        query = json.loads(line.strip())\n",
    "                        queries.append(query)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        logger.warning(f\"Skipping invalid JSON on line {line_num}: {e}\")\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading test queries file: {e}\")\n",
    "            \n",
    "        return queries\n",
    "    \n",
    "    def _load_historical_query_embeddings(self):\n",
    "        \"\"\"FIXED: Load historical query embeddings with better error handling\"\"\"\n",
    "        historical_queries = {}\n",
    "        \n",
    "        # Your query embedding file pattern: q_{test_dataset}_FinQuest_embeddings.pkl\n",
    "        query_file = os.path.join(self.embeddings_dir, f'q_{self.test_dataset}_FinQuest_embeddings.pkl')\n",
    "        \n",
    "        if not os.path.exists(query_file):\n",
    "            logger.error(f\"Query embeddings file not found: {query_file}\")\n",
    "            logger.error(\"Please check:\")\n",
    "            logger.error(f\"1. Embeddings directory exists: {self.embeddings_dir}\")\n",
    "            logger.error(f\"2. File naming matches: q_{self.test_dataset}_{self.embedder_name}_embeddings.pkl\")\n",
    "            logger.error(\"3. Query embeddings were generated successfully\")\n",
    "            return historical_queries\n",
    "        \n",
    "        logger.info(f\"Loading query embeddings: {query_file}\")\n",
    "        try:\n",
    "            with open(query_file, 'rb') as f:\n",
    "                embedding_data = pickle.load(f)\n",
    "            \n",
    "            # Your structure: list of {date: [{'data': query, 'embedding': emb}, ...]}\n",
    "            for date_group in embedding_data:\n",
    "                if not isinstance(date_group, dict):\n",
    "                    logger.warning(f\"Unexpected date_group type: {type(date_group)}\")\n",
    "                    continue\n",
    "                    \n",
    "                for date, queries in date_group.items():\n",
    "                    if not isinstance(queries, list):\n",
    "                        logger.warning(f\"Unexpected queries type for date {date}: {type(queries)}\")\n",
    "                        continue\n",
    "                        \n",
    "                    for query_item in queries:\n",
    "                        if 'data' not in query_item or 'embedding' not in query_item:\n",
    "                            logger.warning(f\"Query item missing required keys: {query_item.keys()}\")\n",
    "                            continue\n",
    "                            \n",
    "                        query_data = query_item['data']\n",
    "                        embedding = torch.tensor(query_item['embedding'], dtype=torch.float32).to(self.device)\n",
    "                        \n",
    "                        # Use data_index as unique identifier (from your data structure)\n",
    "                        query_id = query_data.get('data_index', len(historical_queries))\n",
    "                        historical_queries[query_id] = {\n",
    "                            'data': query_data,\n",
    "                            'embedding': embedding,\n",
    "                            'date': date\n",
    "                        }\n",
    "            \n",
    "            logger.info(f\"Successfully loaded {len(historical_queries)} historical queries\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading query embeddings: {e}\")\n",
    "            \n",
    "        return historical_queries\n",
    "    \n",
    "    def _load_candidate_embeddings(self):\n",
    "        \"\"\"FIXED: Load candidate embeddings with flexible file name matching\"\"\"\n",
    "        candidates = {}\n",
    "        \n",
    "        # Search for candidate embedding files with flexible naming\n",
    "        group = 1\n",
    "        files_loaded = 0\n",
    "        \n",
    "        while True:\n",
    "            possible_candidate_files = [\n",
    "                os.path.join(self.embeddings_dir, f'c_{self.test_dataset}_FinQuest_embeddings_{group}.pkl'),\n",
    "                os.path.join(self.embeddings_dir, f'c_your_dataset_FinQuest_embeddings_{group}.pkl'),\n",
    "            ]\n",
    "            \n",
    "            candidate_file = None\n",
    "            for file_path in possible_candidate_files:\n",
    "                if os.path.exists(file_path):\n",
    "                    candidate_file = file_path\n",
    "                    break\n",
    "            \n",
    "            if candidate_file is None:\n",
    "                break\n",
    "            \n",
    "            logger.info(f\"Loading candidate embeddings: {candidate_file}\")\n",
    "            try:\n",
    "                with open(candidate_file, 'rb') as f:\n",
    "                    embedding_data = pickle.load(f)\n",
    "                \n",
    "                # Your structure: list of {date: [{'data': candidate, 'embedding': emb}, ...]}\n",
    "                for date_group in embedding_data:\n",
    "                    if not isinstance(date_group, dict):\n",
    "                        logger.warning(f\"Unexpected date_group type in file {group}: {type(date_group)}\")\n",
    "                        continue\n",
    "                        \n",
    "                    for date, candidate_list in date_group.items():\n",
    "                        if not isinstance(candidate_list, list):\n",
    "                            logger.warning(f\"Unexpected candidate_list type for date {date}: {type(candidate_list)}\")\n",
    "                            continue\n",
    "                            \n",
    "                        for candidate_item in candidate_list:\n",
    "                            if 'data' not in candidate_item or 'embedding' not in candidate_item:\n",
    "                                logger.warning(f\"Candidate item missing required keys: {candidate_item.keys()}\")\n",
    "                                continue\n",
    "                                \n",
    "                            candidate_data = candidate_item['data']\n",
    "                            embedding = torch.tensor(candidate_item['embedding'], dtype=torch.float32).to(self.device)\n",
    "                            \n",
    "                            # Use data_index as unique identifier\n",
    "                            candidate_id = candidate_data.get('data_index', len(candidates))\n",
    "                            candidates[candidate_id] = {\n",
    "                                'data': candidate_data,\n",
    "                                'embedding': embedding,\n",
    "                                'date': date\n",
    "                            }\n",
    "                \n",
    "                files_loaded += 1\n",
    "                            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading candidate file {group}: {e}\")\n",
    "            \n",
    "            group += 1\n",
    "        \n",
    "        logger.info(f\"Successfully loaded {files_loaded} candidate embedding files with {len(candidates)} total candidates\")\n",
    "        return candidates\n",
    "    \n",
    "    def _get_query_str(self, query):\n",
    "        \"\"\"Convert query dict to string - EXACT COPY from EMBEDDER\"\"\"\n",
    "        if 'query_str' in query:\n",
    "            return query['query_str']\n",
    "        \n",
    "        # Convert from your query format to string\n",
    "        seq_dict = {\n",
    "            'query_stock': query.get('query_stock', 'Unknown'),\n",
    "            'query_date': query.get('query_date', 'Unknown'),\n",
    "            'recent_date_list': query.get('recent_date_list', []),\n",
    "            'adjusted_close_list': query.get('adjusted_close_list', [])\n",
    "        }\n",
    "        return str(seq_dict)\n",
    "    \n",
    "    def _create_query_candidate_mapping(self):\n",
    "        \"\"\"FIXED: Create mapping with better logic and error handling\"\"\"\n",
    "        mapping = defaultdict(list)\n",
    "        \n",
    "        if not self.historical_queries or not self.candidates:\n",
    "            logger.warning(\"Cannot create mapping: missing historical queries or candidates\")\n",
    "            return mapping\n",
    "        \n",
    "        logger.info(\"Creating query-candidate mapping based on dates and stocks...\")\n",
    "        \n",
    "        successful_mappings = 0\n",
    "        \n",
    "        for query_id, query_info in self.historical_queries.items():\n",
    "            query_date = query_info['date']\n",
    "            query_stock = query_info['data'].get('query_stock', '')\n",
    "            \n",
    "            candidates_for_this_query = []\n",
    "            \n",
    "            for candidate_id, candidate_info in self.candidates.items():\n",
    "                candidate_date = candidate_info['date']\n",
    "                candidate_stock = candidate_info['data'].get('candidate_stock', '')\n",
    "                \n",
    "                # Strategy 1: Same date, same stock (primary association)\n",
    "                if (query_date == candidate_date) and (query_stock == candidate_stock):\n",
    "                    candidates_for_this_query.append(candidate_id)\n",
    "                \n",
    "                # Strategy 2: Candidate within 1-3 days before query, same stock\n",
    "                elif query_stock == candidate_stock and query_stock != '':\n",
    "                    try:\n",
    "                        query_dt = datetime.strptime(query_date, \"%Y-%m-%d\")\n",
    "                        candidate_dt = datetime.strptime(candidate_date, \"%Y-%m-%d\")\n",
    "                        date_diff = (query_dt - candidate_dt).days\n",
    "                        if 0 <= date_diff <= 3:\n",
    "                            candidates_for_this_query.append(candidate_id)\n",
    "                    except ValueError as e:\n",
    "                        # Skip invalid date formats\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        # Skip other date processing errors\n",
    "                        continue\n",
    "            \n",
    "            if candidates_for_this_query:\n",
    "                mapping[query_id] = candidates_for_this_query\n",
    "                successful_mappings += 1\n",
    "        \n",
    "        # Log statistics\n",
    "        total_queries = len(self.historical_queries)\n",
    "        mapped_queries = len(mapping)\n",
    "        \n",
    "        if mapping:\n",
    "            avg_candidates = np.mean([len(candidates) for candidates in mapping.values()])\n",
    "            max_candidates = max([len(candidates) for candidates in mapping.values()])\n",
    "        else:\n",
    "            avg_candidates = 0\n",
    "            max_candidates = 0\n",
    "        \n",
    "        logger.info(f\"Mapping Statistics:\")\n",
    "        logger.info(f\"  Total historical queries: {total_queries}\")\n",
    "        logger.info(f\"  Queries with candidates: {mapped_queries} ({mapped_queries/total_queries*100:.1f}%)\")\n",
    "        logger.info(f\"  Average candidates per query: {avg_candidates:.1f}\")\n",
    "        logger.info(f\"  Max candidates for any query: {max_candidates}\")\n",
    "        \n",
    "        if mapped_queries == 0:\n",
    "            logger.warning(\"‚ö†Ô∏è  No query-candidate mappings created!\")\n",
    "            logger.warning(\"This could indicate:\")\n",
    "            logger.warning(\"1. Date format mismatches between queries and candidates\")\n",
    "            logger.warning(\"2. Stock symbol mismatches\")\n",
    "            logger.warning(\"3. No overlapping dates in your data\")\n",
    "            \n",
    "            # Show sample data for debugging\n",
    "            if self.historical_queries:\n",
    "                sample_query = next(iter(self.historical_queries.values()))\n",
    "                logger.info(f\"Sample query date format: {sample_query['date']}\")\n",
    "                logger.info(f\"Sample query stock: {sample_query['data'].get('query_stock', 'N/A')}\")\n",
    "            \n",
    "            if self.candidates:\n",
    "                sample_candidate = next(iter(self.candidates.values()))\n",
    "                logger.info(f\"Sample candidate date format: {sample_candidate['date']}\")\n",
    "                logger.info(f\"Sample candidate stock: {sample_candidate['data'].get('candidate_stock', 'N/A')}\")\n",
    "        \n",
    "        return mapping\n",
    "    \n",
    "    def encode_test_query(self, test_query):\n",
    "        \"\"\"Encode a new test query using the same method as embedding generation\"\"\"\n",
    "        query_str = self._get_query_str(test_query)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embedding = self.model.encode_sequence([query_str])\n",
    "        \n",
    "        return embedding[0]\n",
    "    \n",
    "    def find_similar_historical_queries(self, test_query, top_k=20):\n",
    "        \"\"\"Find most similar historical queries to a test query\"\"\"\n",
    "        if not self.historical_queries:\n",
    "            logger.warning(\"No historical queries available for similarity search\")\n",
    "            return []\n",
    "            \n",
    "        test_embedding = self.encode_test_query(test_query)\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        for query_id, query_info in self.historical_queries.items():\n",
    "            historical_embedding = query_info['embedding']\n",
    "            \n",
    "            # Calculate cosine similarity (same as your training)\n",
    "            similarity = torch.cosine_similarity(\n",
    "                test_embedding.unsqueeze(0), \n",
    "                historical_embedding.unsqueeze(0)\n",
    "            ).item()\n",
    "            \n",
    "            similarities.append({\n",
    "                'query_id': query_id,\n",
    "                'similarity': similarity,\n",
    "                'historical_query': query_info['data'],\n",
    "                'date': query_info['date']\n",
    "            })\n",
    "        \n",
    "        # Sort by similarity and return top-K\n",
    "        similarities.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "    \n",
    "    def retrieve_candidates_from_similar_queries(self, similar_queries, top_k=10):\n",
    "        \"\"\"Retrieve candidates associated with similar historical queries\"\"\"\n",
    "        if not similar_queries:\n",
    "            return []\n",
    "            \n",
    "        candidate_scores = defaultdict(float)\n",
    "        candidate_info = {}\n",
    "        \n",
    "        for similar_query in similar_queries:\n",
    "            query_id = similar_query['query_id']\n",
    "            query_similarity = similar_query['similarity']\n",
    "            \n",
    "            # Get candidates associated with this historical query\n",
    "            associated_candidate_ids = self.query_candidate_mapping.get(query_id, [])\n",
    "            \n",
    "            for candidate_id in associated_candidate_ids:\n",
    "                if candidate_id in self.candidates:\n",
    "                    # Use max similarity as candidate score\n",
    "                    candidate_scores[candidate_id] = max(\n",
    "                        candidate_scores[candidate_id], \n",
    "                        query_similarity\n",
    "                    )\n",
    "                    candidate_info[candidate_id] = self.candidates[candidate_id]\n",
    "        \n",
    "        # Create final candidate list\n",
    "        final_candidates = []\n",
    "        for candidate_id, score in candidate_scores.items():\n",
    "            final_candidates.append({\n",
    "                'candidate_index': candidate_id,  # Match your expected output format\n",
    "                'candidate_score': score,         # Match your expected output format\n",
    "                'candidate_data': candidate_info[candidate_id]['data'],\n",
    "                'candidate_date': candidate_info[candidate_id]['date']\n",
    "            })\n",
    "        \n",
    "        # Sort by score and return top-K\n",
    "        final_candidates.sort(key=lambda x: x['candidate_score'], reverse=True)\n",
    "        return final_candidates[:top_k]\n",
    "    \n",
    "    def search_all_test_queries(self, top_k_queries=20, top_k_candidates=10):\n",
    "        \"\"\"FIXED: Run similarity search for all test queries with better error handling\"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        if not self.test_queries:\n",
    "            logger.error(\"No test queries to process\")\n",
    "            return all_results\n",
    "        \n",
    "        logger.info(f\"Processing {len(self.test_queries)} test queries...\")\n",
    "        \n",
    "        queries_with_candidates = 0\n",
    "        \n",
    "        for i, test_query in enumerate(self.test_queries):\n",
    "            if (i + 1) % 100 == 0:\n",
    "                logger.info(f\"Processed {i + 1}/{len(self.test_queries)} queries\")\n",
    "            \n",
    "            # Step 1: Find similar historical queries\n",
    "            similar_queries = self.find_similar_historical_queries(test_query, top_k_queries)\n",
    "            \n",
    "            if not similar_queries:\n",
    "                logger.warning(f\"No similar queries found for test query {i}\")\n",
    "                all_results.append({\n",
    "                    'query_id': test_query.get('query_id', f\"query_{test_query.get('data_index', i)}\"),\n",
    "                    'query_index': test_query.get('data_index', i),\n",
    "                    'query_stock': test_query.get('query_stock', 'Unknown'),\n",
    "                    'query_date': test_query.get('query_date', 'Unknown'),\n",
    "                    'similarity_list': [],\n",
    "                    'total_candidates_searched': 0\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Step 2: Retrieve candidates from similar queries\n",
    "            candidates = self.retrieve_candidates_from_similar_queries(similar_queries, top_k_candidates)\n",
    "            \n",
    "            if candidates:\n",
    "                queries_with_candidates += 1\n",
    "            \n",
    "            # Format result to match your expected structure\n",
    "            result = {\n",
    "                'query_id': test_query.get('query_id', f\"query_{test_query.get('data_index', i)}\"),\n",
    "                'query_index': test_query.get('data_index', i),\n",
    "                'query_stock': test_query.get('query_stock', 'Unknown'),\n",
    "                'query_date': test_query.get('query_date', 'Unknown'),\n",
    "                'similarity_list': candidates,  # This matches your original output format\n",
    "                'total_candidates_searched': len(candidates)\n",
    "            }\n",
    "            \n",
    "            all_results.append(result)\n",
    "        \n",
    "        logger.info(f\"Completed similarity search for {len(all_results)} test queries\")\n",
    "        logger.info(f\"Queries with candidates found: {queries_with_candidates}/{len(all_results)} ({queries_with_candidates/len(all_results)*100:.1f}%)\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_similarity_results(self, similarity_results, output_file):\n",
    "        \"\"\"Save similarity results to pickle file - same as your original\"\"\"\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(similarity_results, f)\n",
    "        \n",
    "        logger.info(f\"Saved results to: {output_file}\")\n",
    "    \n",
    "    def analyze_results(self, results):\n",
    "        \"\"\"FIXED: Better analysis with more detailed statistics\"\"\"\n",
    "        if not results:\n",
    "            logger.warning(\"No results to analyze\")\n",
    "            return\n",
    "        \n",
    "        total_queries = len(results)\n",
    "        queries_with_candidates = sum(1 for r in results if r['similarity_list'])\n",
    "        \n",
    "        if queries_with_candidates > 0:\n",
    "            avg_candidates = np.mean([len(r['similarity_list']) for r in results if r['similarity_list']])\n",
    "            max_candidates = max([len(r['similarity_list']) for r in results])\n",
    "            min_candidates = min([len(r['similarity_list']) for r in results if r['similarity_list']])\n",
    "        else:\n",
    "            avg_candidates = max_candidates = min_candidates = 0\n",
    "        \n",
    "        logger.info(\"=\"*50)\n",
    "        logger.info(\"RETRIEVAL-BASED SEARCH RESULTS ANALYSIS\")\n",
    "        logger.info(\"=\"*50)\n",
    "        logger.info(f\"Total test queries processed: {total_queries}\")\n",
    "        logger.info(f\"Queries with candidates found: {queries_with_candidates} ({queries_with_candidates/total_queries*100:.1f}%)\")\n",
    "        logger.info(f\"Queries with no candidates: {total_queries - queries_with_candidates}\")\n",
    "        logger.info(f\"Average candidates per successful query: {avg_candidates:.1f}\")\n",
    "        logger.info(f\"Max candidates for any query: {max_candidates}\")\n",
    "        logger.info(f\"Min candidates for successful queries: {min_candidates}\")\n",
    "        \n",
    "        # Show sample result\n",
    "        successful_results = [r for r in results if r['similarity_list']]\n",
    "        if successful_results:\n",
    "            sample = successful_results[0]\n",
    "            logger.info(\"\\nSAMPLE SUCCESSFUL RESULT:\")\n",
    "            logger.info(f\"Test query: {sample['query_stock']} on {sample['query_date']}\")\n",
    "            logger.info(f\"Found {len(sample['similarity_list'])} candidates\")\n",
    "            \n",
    "            if sample['similarity_list']:\n",
    "                top_candidate = sample['similarity_list'][0]\n",
    "                logger.info(f\"Top candidate: Index {top_candidate['candidate_index']} (score: {top_candidate['candidate_score']:.3f})\")\n",
    "        \n",
    "        # Debugging info if no results found\n",
    "        if queries_with_candidates == 0:\n",
    "            logger.warning(\"\\n‚ö†Ô∏è  NO CANDIDATES FOUND FOR ANY QUERIES!\")\n",
    "            logger.warning(\"This suggests an issue with:\")\n",
    "            logger.warning(\"1. Query-candidate mapping creation\")\n",
    "            logger.warning(\"2. Historical data loading\")\n",
    "            logger.warning(\"3. Date/stock matching logic\")\n",
    "\n",
    "def run_retrieval_search():\n",
    "    \"\"\"FIXED: Main function with comprehensive error checking\"\"\"\n",
    "    \n",
    "    # Configuration - aligned with your paths and structure\n",
    "    test_queries_file = '/root/nfs/AJ FinRag/Evaluation Results/Test Queries/test_queries_rise_fall_only.json'\n",
    "    test_dataset = 'your_dataset'\n",
    "    embedder_name = 'FinQuest'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Output configuration\n",
    "    output_dir = 'similar_candidates/test/FinQuest'\n",
    "    output_file = os.path.join(output_dir, 'test_similarity_results_FinQuest.pkl')\n",
    "    \n",
    "    logger.info(\"üöÄ Starting Retrieval-Based Similarity Search\")\n",
    "    logger.info(\"=\"*60)\n",
    "    \n",
    "    # COMPREHENSIVE PRE-FLIGHT CHECKS\n",
    "    \n",
    "    # Check 1: Test queries file\n",
    "    if not os.path.exists(test_queries_file):\n",
    "        logger.error(f\"‚ùå Test queries file not found: {test_queries_file}\")\n",
    "        return None\n",
    "    \n",
    "    # Check 2: Embeddings directory\n",
    "    embeddings_dir = '/root/nfs/AJ FinRag/Embeddings/embeddings/test/FinQuest'\n",
    "    if not os.path.exists(embeddings_dir):\n",
    "        logger.error(f\"‚ùå Embeddings directory not found: {embeddings_dir}\")\n",
    "        logger.error(\"Run embedding generation first!\")\n",
    "        return None\n",
    "    \n",
    "    # Check 3: Query embeddings - flexible search\n",
    "    import glob\n",
    "    query_pattern = os.path.join(embeddings_dir, 'q_*_FinQuest_embeddings.pkl')\n",
    "    query_files = glob.glob(query_pattern)\n",
    "    \n",
    "    if not query_files:\n",
    "        logger.error(f\"‚ùå No query embeddings found in: {embeddings_dir}\")\n",
    "        logger.error(\"Looked for pattern: q_*_FinQuest_embeddings.pkl\")\n",
    "        \n",
    "        # List actual files for debugging\n",
    "        if os.path.exists(embeddings_dir):\n",
    "            actual_files = [f for f in os.listdir(embeddings_dir) if f.endswith('.pkl')]\n",
    "            logger.error(f\"Actual .pkl files found: {actual_files}\")\n",
    "        \n",
    "        logger.error(\"Generate query embeddings first: get_embeddings(dataset, 'FinQuest', 'query', device)\")\n",
    "        return None\n",
    "    \n",
    "    query_file = query_files[0]  # Use first match\n",
    "    \n",
    "    # Check 4: Candidate embeddings - flexible search\n",
    "    candidate_pattern = os.path.join(embeddings_dir, 'c_*_FinQuest_embeddings_1.pkl')\n",
    "    candidate_files = glob.glob(candidate_pattern)\n",
    "    \n",
    "    if not candidate_files:\n",
    "        logger.error(f\"‚ùå No candidate embeddings found in: {embeddings_dir}\")\n",
    "        logger.error(\"Looked for pattern: c_*_FinQuest_embeddings_1.pkl\")\n",
    "        logger.error(\"Generate candidate embeddings first: get_embeddings(dataset, 'FinQuest', 'candidate', device)\")\n",
    "        return None\n",
    "    \n",
    "    # Check 5: Model file\n",
    "    model_path = '/root/nfs/AJ FinRag/Models/finquest_models/finquest_retriever_best.pth'\n",
    "    if not os.path.exists(model_path):\n",
    "        logger.error(f\"‚ùå Model file not found: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "    logger.info(f\"‚úÖ All files found - proceeding with search\")\n",
    "    logger.info(f\"‚úÖ Test queries: {test_queries_file}\")\n",
    "    logger.info(f\"‚úÖ Query embeddings: {query_file}\")\n",
    "    logger.info(f\"‚úÖ Candidate embeddings: {embeddings_dir}\")\n",
    "    logger.info(f\"‚úÖ Model: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize search system\n",
    "        search_system = RetrievalBasedSimilaritySearch(\n",
    "            test_queries_file=test_queries_file,\n",
    "            test_dataset=test_dataset,\n",
    "            embedder_name=embedder_name,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Verify system is properly initialized\n",
    "        if len(search_system.historical_queries) == 0:\n",
    "            logger.error(\"‚ùå No historical queries loaded - cannot proceed\")\n",
    "            return None\n",
    "            \n",
    "        if len(search_system.candidates) == 0:\n",
    "            logger.error(\"‚ùå No candidates loaded - cannot proceed\")\n",
    "            return None\n",
    "            \n",
    "        if len(search_system.query_candidate_mapping) == 0:\n",
    "            logger.error(\"‚ùå No query-candidate mappings created - cannot proceed\")\n",
    "            return None\n",
    "        \n",
    "        # Run search with same parameters as your original\n",
    "        logger.info(\"Running similarity search...\")\n",
    "        results = search_system.search_all_test_queries(\n",
    "            top_k_queries=20,    # Find top 20 similar historical queries\n",
    "            top_k_candidates=10  # Retrieve top 10 candidates (save_top_k equivalent)\n",
    "        )\n",
    "        \n",
    "        # Analyze results\n",
    "        search_system.analyze_results(results)\n",
    "        \n",
    "        # Save results using the same format as your original\n",
    "        search_system.save_similarity_results(results, output_file)\n",
    "        \n",
    "        logger.info(\"üéâ Retrieval-based similarity search completed successfully!\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error in similarity search: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set multiprocessing method (same as your embedding code)\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "    \n",
    "    results = run_retrieval_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d81fb-7e26-406b-9468-078893eb0815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
